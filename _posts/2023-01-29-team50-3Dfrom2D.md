---
layout: post
comments: true
title: Generating 3D Models of Humans from 2D Video
author: Bryce Stulman
date: 2023-01-29
---

> This blog will document my exploration of using machine learning to generate 3D models of people in motion from 2D videos. The goal is to generate 3D models using pose and shape estimation using so called monocular (single lens/perspective) video.


<!--more-->

{: class="table-of-content"}
* TOC
{:toc}

---
## Relevant Papers
**[1] Learning 3D Human Dynamics from Video**

[paper] - https://openaccess.thecvf.com/content_CVPR_2019/html/Kanazawa_Learning_3D_Human_Dynamics_From_Video_CVPR_2019_paper.html

[code] - https://github.com/akanazawa/human_dynamics

**[2] Capturing Humans in Motion: Temporal-Attentive 3D Human Pose and Shape Estimation from Monocular Video**

[paper] - https://openaccess.thecvf.com/content/CVPR2022/html/Wei_Capturing_Humans_in_Motion_Temporal-Attentive_3D_Human_Pose_and_Shape_CVPR_2022_paper.html

[code] - https://github.com/MPS-Net/MPS-Net_release

**[3] Recent Advances in Monocular 2D and 3D Human Pose Estimation: A Deep Learning Perspective**

[paper] - https://arxiv.org/abs/2104.11536


---
## References
[1] Kanazawa, Angjoo, et al. "Learning 3d human dynamics from video." *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition.* 2019.

[2] Wei, Wen-Li, et al. "Capturing humans in motion: temporal-attentive 3D human pose and shape estimation from monocular video." *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.* 2022.

[3] Liu, Wu, et al. "Recent advances of monocular 2d and 3d human pose estimation: a deep learning perspective." *ACM Computing Surveys* 55.4 (2022): 1-41.

---
