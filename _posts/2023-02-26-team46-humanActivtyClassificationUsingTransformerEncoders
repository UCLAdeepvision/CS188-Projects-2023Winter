---
layout: post
comments: true
title: Human Activty Classification Using Transformer Encoders
author: Lukas Brockenbrough, Laurence Yang
date: 2023-02-26
---

<!--more-->
{: class="table-of-content"}
* TOC
{:toc}

## Introduction
Our project idea is to classify images of humans by the activity they are performing. We will use several different image encoder models, all of which use transformers, to see which will have the best results. We also will use various feature selection heads to classify the encoded images. We will use the Stanford 40 Actions dataset in order to train and evaluate our model. Our goal is to find which combination of encoder and feature selection head is best for a human activity image classification model.

![Beit in Architecture](../assets/images/46/BeitInArchitecture.png)

## Encoders
- (Big Encoder-Transformer): BEiT is a transformer-based image encoder model that was introduced in 2021 by the Microsoft Research team. Its architecture is based on the ideas used in the architecture of BERT, a similar encoder for text. It consists of a large number of parameters and can be trained on large datasets to achieve state-of-the-art performance on various vision tasks. BEiT uses a hybrid architecture that combines convolutional layers with transformer layers, allowing it to process images of different resolutions.

- ViT (Vision Transformer): ViT is a transformer-based image encoder model that was introduced in 2020 by the Google Brain team. It was one of the first transformer-based models to achieve state-of-the-art performance on image classification tasks. ViT uses a pure transformer architecture, which means it only uses transformer layers to process images. It divides the input image into fixed-size patches and processes them using self-attention mechanisms.

- DeiT (Data-efficient image Transformers): DeiT is a transformer-based image encoder model that was introduced in 2021 by the Facebook AI team. It is designed to be more data-efficient than previous transformer-based models, which means it can achieve state-of-the-art performance with smaller amounts of training data. DeiT uses a distilled training approach, which means it is trained on a smaller teacher model to improve its performance.

## Feature Selection Heads
- Linear layers: We will use several linear layers to classify the encoded images into 40 activity classes.

- CNN: We will use a convolutional neural network model to classify the encoded images into 40 activity classes.

- Resnet-50: We will use Resnet-50 to classify the encoded images into 40 activity classes.

## Sample Code
import timm
import torch.nn as nn
import torch.nn.functional as F
  
class Model(nn.Module):
    def __init__(
        self,
        num_classes,
        beit_version="beitv2_base_patch16_224_in22k",
        head=None
    ):
        if head is None:
            head = nn.Sequential(
                nn.Flatten(),
                nn.Linear(768, num_classes)
            )
        super().__init__()
        self.encoder = timm.create_model(
            beit_version,
            num_classes=0
        ).to("cuda:0")
        self.encoder.requires_grad_(False)
        self.head = head

    def forward(self, image):
        tokens = self.encoder(image).detach()
        return self.head(tokens)

## References
- https://arxiv.org/abs/2106.08254
- https://arxiv.org/abs/2010.11929
---
