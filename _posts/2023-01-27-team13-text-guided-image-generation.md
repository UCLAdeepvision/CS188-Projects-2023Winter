---
layout: post
comments: true
title: Text Guided Image Generation
author: Isaac Li, Ivana Chang
date: 2022-01-27
---


> Diffusion models have been shown to be extremely powerful for image synthesis. In this article, we take an in depth look at diffusion models as a means of generating realistic and relevant images from natural language.


<!--more-->
{: class="table-of-content"}
* TOC
{:toc}

<!-- [1] Redmon, Joseph, et al. "You only look once: Unified, real-time object detection." *Proceedings of the IEEE conference on computer vision and pattern recognition*. 2016. -->
## Relevant Papers 
1. GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models
- [Paper](https://arxiv.org/abs/2112.10741)
- [Code](https://github.com/openai/glide-text2im)

2. Learning Transferable Visual Models From Natural Language Supervision
- [Paper](https://arxiv.org/abs/2103.00020)
- [Code](https://github.com/openai/clip)

3. Diffusion Models Beat GANs on Image Synthesis
- [Paper](https://arxiv.org/abs/2105.05233)


---
