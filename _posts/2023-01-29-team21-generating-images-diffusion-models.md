---
layout: post
comments: true
title: Generating Images with Diffusion Models
author: Evan He, Samarth Upadhyaya
date: 2017-06-21 01:09:00
---

> This project focuses on the generation of images from text using diffusion models.

<!--more-->

## Most Influential Papers

[High-Resolution Image Synthesis with Latent Diffusion Models]("https://arxiv.org/abs/2112.10752") | [Code]("https://github.com/CompVis/latent-diffusion")

This paper covers the use of latent diffusion models to achieve a balance between performance and computational complexity in image generation.

[Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis]("https://arxiv.org/abs/2212.05032") | [Code]("https://github.com/shunk031/training-free-structured-diffusion-guidance)

This paper covers incorporating linguistic structures to manipulate a model's image compositional capabilities.

[Compositional Visual Generation with Composable Diffusion Models]("https://arxiv.org/abs/2206.01714") | [Code]("https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch")

This paper covers image generation through a composite of several diffusion models that each model a portion of the image.